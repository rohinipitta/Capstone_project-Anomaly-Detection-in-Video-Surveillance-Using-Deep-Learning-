{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9646b8d-e889-41c5-b7a4-0988beeddc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohini\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.4.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rohini\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohini\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81561cf4-f8aa-49fb-b5fd-ec2ac6bd391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb0115a-7c01-44bd-9160-48cd5f9f4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Step 1: Define the Dataset Class\n",
    "class VideoFrameDataset(Dataset):\n",
    "    def __init__(self, frame_paths, labels, transform=None):\n",
    "        self.frame_paths = frame_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        frame_path = self.frame_paths[idx]\n",
    "        image = Image.open(frame_path).convert(\"RGB\")\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Load label\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Step 2: Gather all frame paths and labels\n",
    "root_dir = \"C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\"  # Replace with your base folder\n",
    "classes = {\"frames_abuse\": 0, \"frames_arrest\": 1, \"frames_normal\": 2}\n",
    "frame_paths = []\n",
    "labels = []\n",
    "\n",
    "for class_folder, label in classes.items():\n",
    "    class_path = os.path.join(root_dir, class_folder)\n",
    "    if not os.path.exists(class_path):\n",
    "        print(f\"Warning: Directory not found: {class_path}\")\n",
    "        continue\n",
    "\n",
    "    for video_folder in os.listdir(class_path):\n",
    "        video_path = os.path.join(class_path, video_folder)\n",
    "        if not os.path.isdir(video_path):\n",
    "            continue\n",
    "        \n",
    "        # Collect all frames within the video folder\n",
    "        for frame_file in os.listdir(video_path):\n",
    "            if frame_file.endswith(\".jpg\"):\n",
    "                frame_paths.append(os.path.join(video_path, frame_file))\n",
    "                labels.append(label)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0316d94-a6b7-4d13-a7c3-18df8f5c5712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: frames_abuse (Label: 0)\n",
      "  Video Folder: Abuse001_x264\n",
      "  Video Folder: Abuse002_x264\n",
      "  Video Folder: Abuse003_x264\n",
      "  Video Folder: Abuse004_x264\n",
      "  Video Folder: Abuse005_x264\n",
      "  Video Folder: Abuse006_x264\n",
      "  Video Folder: Abuse007_x264\n",
      "  Video Folder: Abuse008_x264\n",
      "  Video Folder: Abuse009_x264\n",
      "  Video Folder: Abuse010_x264\n",
      "\n",
      "Class: frames_arrest (Label: 1)\n",
      "  Video Folder: Arrest001_x264\n",
      "  Video Folder: Arrest002_x264\n",
      "  Video Folder: Arrest003_x264\n",
      "  Video Folder: Arrest004_x264\n",
      "  Video Folder: Arrest005_x264\n",
      "  Video Folder: Arrest006_x264\n",
      "  Video Folder: Arrest007_x264\n",
      "  Video Folder: Arrest008_x264\n",
      "  Video Folder: Arrest009_x264\n",
      "  Video Folder: Arrest010_x264\n",
      "\n",
      "Class: frames_normal (Label: 2)\n",
      "  Video Folder: Normal_Videos_003_x264\n",
      "  Video Folder: Normal_Videos_006_x264\n",
      "  Video Folder: Normal_Videos_010_x264\n",
      "  Video Folder: Normal_Videos_014_x264\n",
      "  Video Folder: Normal_Videos_015_x264\n",
      "  Video Folder: Normal_Videos_018_x264\n",
      "  Video Folder: Normal_Videos_019_x264\n",
      "  Video Folder: Normal_Videos_024_x264\n",
      "  Video Folder: Normal_Videos_025_x264\n",
      "  Video Folder: Normal_Videos_027_x264\n",
      "  Video Folder: Normal_Videos_033_x264\n",
      "  Video Folder: Normal_Videos_034_x264\n",
      "  Video Folder: Normal_Videos_041_x264\n",
      "  Video Folder: Normal_Videos_042_x264\n",
      "  Video Folder: Normal_Videos_048_x264\n",
      "  Video Folder: Normal_Videos_050_x264\n",
      "  Video Folder: Normal_Videos_051_x264\n",
      "  Video Folder: Normal_Videos_056_x264\n",
      "  Video Folder: Normal_Videos_059_x264\n",
      "  Video Folder: Normal_Videos_063_x264\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 10  # Number of frames per sequence (adjust based on your data)\n",
    "frame_sequences = []  # List to store sequences of frames\n",
    "sequence_labels = []  # List to store labels for each sequence\n",
    "\n",
    "for class_folder, label in classes.items():\n",
    "    class_path = os.path.join(root_dir, class_folder)\n",
    "    if not os.path.exists(class_path):\n",
    "        print(f\"Warning: Directory not found: {class_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nClass: {class_folder} (Label: {label})\")\n",
    "    for video_folder in os.listdir(class_path):\n",
    "        video_path = os.path.join(class_path, video_folder)\n",
    "        if not os.path.isdir(video_path):\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Video Folder: {video_folder}\")  # Print video folder names\n",
    "\n",
    "        # Collect all frames within the video folder\n",
    "        video_frames = [\n",
    "            os.path.join(video_path, frame_file)\n",
    "            for frame_file in sorted(os.listdir(video_path))\n",
    "            if frame_file.endswith(\".jpg\")\n",
    "        ]\n",
    "\n",
    "        # Split frames into sequences\n",
    "        for i in range(0, len(video_frames) - sequence_length + 1, sequence_length):\n",
    "            frame_sequences.append(video_frames[i:i + sequence_length])\n",
    "            sequence_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7181ea71-3ddf-4319-8dd1-4b9634707710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoSequenceDataset(Dataset):\n",
    "    def __init__(self, frame_sequences, labels, transform=None):\n",
    "        self.frame_sequences = frame_sequences\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the sequence of frame paths\n",
    "        sequence_paths = self.frame_sequences[idx]\n",
    "        frames = []\n",
    "        for frame_path in sequence_paths:\n",
    "            frame = Image.open(frame_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            frames.append(frame)\n",
    "\n",
    "        # Stack frames into a tensor: (sequence_length, C, H, W)\n",
    "        frames_tensor = torch.stack(frames)\n",
    "        label = self.labels[idx]\n",
    "        return frames_tensor, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1f5c050-d922-4162-9cd3-0216a649f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(frame_paths, labels, sequence_length=10):\n",
    "    \"\"\"\n",
    "    Groups frames into sequences for temporal modeling with debug information.\n",
    "\n",
    "    Args:\n",
    "        frame_paths (list): List of frame paths.\n",
    "        labels (list): Corresponding labels for each frame.\n",
    "        sequence_length (int): Number of frames in each sequence.\n",
    "\n",
    "    Returns:\n",
    "        sequences (list): List of sequences (each sequence is a list of frame paths).\n",
    "        sequence_labels (list): Labels corresponding to each sequence.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    sequence_labels = []\n",
    "    video_to_frames = {}\n",
    "    video_to_label = {}\n",
    "\n",
    "    # Debug: Print initial input sizes\n",
    "    print(f\"Number of frame paths: {len(frame_paths)}, Number of labels: {len(labels)}\")\n",
    "\n",
    "    # Group frames by video folder\n",
    "    for frame_path, label in zip(frame_paths, labels):\n",
    "        video_folder = os.path.dirname(frame_path)\n",
    "        if video_folder not in video_to_frames:\n",
    "            video_to_frames[video_folder] = []\n",
    "            video_to_label[video_folder] = label\n",
    "        video_to_frames[video_folder].append(frame_path)\n",
    "\n",
    "    # Debug: Print number of videos identified\n",
    "    print(f\"Number of videos: {len(video_to_frames)}\")\n",
    "\n",
    "    # Create sequences\n",
    "    for video_folder, frames in video_to_frames.items():\n",
    "        frames = sorted(frames)  # Ensure frames are in temporal order\n",
    "        num_sequences = (len(frames) - sequence_length + 1) // sequence_length\n",
    "\n",
    "        # Debug: Print sequence information for each video\n",
    "        print(f\"Video: {video_folder}, Total Frames: {len(frames)}, Sequences: {num_sequences}\")\n",
    "\n",
    "        for i in range(0, len(frames) - sequence_length + 1, sequence_length):\n",
    "            sequences.append(frames[i:i + sequence_length])\n",
    "            sequence_labels.append(video_to_label[video_folder])\n",
    "\n",
    "    # Debug: Print final counts\n",
    "    print(f\"Total sequences created: {len(sequences)}, Total sequence labels: {len(sequence_labels)}\")\n",
    "    return sequences, sequence_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a0d02b9-884c-4a09-b794-28eeec5650df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sequences for training set...\n",
      "Number of frame paths: 2151, Number of labels: 2151\n",
      "Number of videos: 40\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse006_x264, Total Frames: 90, Sequences: 8\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse004_x264, Total Frames: 297, Sequences: 28\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_033_x264, Total Frames: 37, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest008_x264, Total Frames: 144, Sequences: 13\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse003_x264, Total Frames: 75, Sequences: 6\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse008_x264, Total Frames: 165, Sequences: 15\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_027_x264, Total Frames: 90, Sequences: 8\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_003_x264, Total Frames: 59, Sequences: 5\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest009_x264, Total Frames: 40, Sequences: 3\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse007_x264, Total Frames: 20, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest010_x264, Total Frames: 58, Sequences: 4\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_024_x264, Total Frames: 28, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_051_x264, Total Frames: 49, Sequences: 4\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_050_x264, Total Frames: 90, Sequences: 8\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_034_x264, Total Frames: 30, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest007_x264, Total Frames: 60, Sequences: 5\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_015_x264, Total Frames: 10, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest001_x264, Total Frames: 51, Sequences: 4\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse009_x264, Total Frames: 23, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_014_x264, Total Frames: 27, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse001_x264, Total Frames: 52, Sequences: 4\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_048_x264, Total Frames: 35, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_019_x264, Total Frames: 54, Sequences: 4\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest006_x264, Total Frames: 61, Sequences: 5\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_042_x264, Total Frames: 63, Sequences: 5\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest003_x264, Total Frames: 60, Sequences: 5\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_056_x264, Total Frames: 31, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest002_x264, Total Frames: 26, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_006_x264, Total Frames: 10, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest004_x264, Total Frames: 58, Sequences: 4\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse002_x264, Total Frames: 17, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest005_x264, Total Frames: 76, Sequences: 6\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_010_x264, Total Frames: 17, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_059_x264, Total Frames: 40, Sequences: 3\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_041_x264, Total Frames: 29, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_018_x264, Total Frames: 20, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse010_x264, Total Frames: 20, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse005_x264, Total Frames: 19, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_063_x264, Total Frames: 8, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_025_x264, Total Frames: 12, Sequences: 0\n",
      "Total sequences created: 200, Total sequence labels: 200\n",
      "\n",
      "Sample training sequence paths:\n",
      "[['C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1020.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1050.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1170.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1200.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1260.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1320.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1350.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1380.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1440.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1470.jpg'], ['C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1530.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1560.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1620.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1650.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1680.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1770.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1800.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1830.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_1980.jpg', 'C:\\\\Users\\\\Rohini\\\\capstone_Project\\\\prjct2\\\\frames\\\\frames_abuse\\\\Abuse006_x264\\\\frame_2070.jpg']]\n",
      "\n",
      "Sample training labels:\n",
      "[0, 0]\n",
      "\n",
      "Creating sequences for validation set...\n",
      "Number of frame paths: 717, Number of labels: 717\n",
      "Number of videos: 40\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse002_x264, Total Frames: 8, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest005_x264, Total Frames: 27, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_051_x264, Total Frames: 12, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_059_x264, Total Frames: 13, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest004_x264, Total Frames: 33, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest010_x264, Total Frames: 15, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_048_x264, Total Frames: 9, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest007_x264, Total Frames: 20, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse008_x264, Total Frames: 56, Sequences: 4\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest008_x264, Total Frames: 33, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse004_x264, Total Frames: 94, Sequences: 8\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest009_x264, Total Frames: 7, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest002_x264, Total Frames: 18, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_019_x264, Total Frames: 25, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_025_x264, Total Frames: 5, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse006_x264, Total Frames: 25, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest001_x264, Total Frames: 22, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_042_x264, Total Frames: 19, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_034_x264, Total Frames: 7, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse001_x264, Total Frames: 17, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse003_x264, Total Frames: 18, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_041_x264, Total Frames: 9, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_050_x264, Total Frames: 24, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_056_x264, Total Frames: 12, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_027_x264, Total Frames: 40, Sequences: 3\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_010_x264, Total Frames: 8, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse009_x264, Total Frames: 6, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse007_x264, Total Frames: 9, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_033_x264, Total Frames: 10, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest003_x264, Total Frames: 21, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest006_x264, Total Frames: 25, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_018_x264, Total Frames: 12, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_014_x264, Total Frames: 11, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_003_x264, Total Frames: 20, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse005_x264, Total Frames: 6, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_006_x264, Total Frames: 2, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse010_x264, Total Frames: 12, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_015_x264, Total Frames: 2, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_024_x264, Total Frames: 4, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_063_x264, Total Frames: 1, Sequences: -1\n",
      "Total sequences created: 54, Total sequence labels: 54\n",
      "\n",
      "Creating sequences for testing set...\n",
      "Number of frame paths: 718, Number of labels: 718\n",
      "Number of videos: 40\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_042_x264, Total Frames: 24, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse007_x264, Total Frames: 10, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse003_x264, Total Frames: 31, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_027_x264, Total Frames: 35, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse001_x264, Total Frames: 22, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse008_x264, Total Frames: 60, Sequences: 5\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_014_x264, Total Frames: 12, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_050_x264, Total Frames: 26, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest002_x264, Total Frames: 16, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest007_x264, Total Frames: 25, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest008_x264, Total Frames: 36, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse004_x264, Total Frames: 109, Sequences: 10\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest006_x264, Total Frames: 17, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_019_x264, Total Frames: 16, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse006_x264, Total Frames: 31, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest003_x264, Total Frames: 21, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_025_x264, Total Frames: 4, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_048_x264, Total Frames: 11, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest005_x264, Total Frames: 20, Sequences: 1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest010_x264, Total Frames: 15, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_003_x264, Total Frames: 16, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_051_x264, Total Frames: 18, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest009_x264, Total Frames: 11, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse010_x264, Total Frames: 6, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse005_x264, Total Frames: 7, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest004_x264, Total Frames: 30, Sequences: 2\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_063_x264, Total Frames: 3, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse002_x264, Total Frames: 4, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_034_x264, Total Frames: 7, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_006_x264, Total Frames: 3, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_arrest\\Arrest001_x264, Total Frames: 7, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_033_x264, Total Frames: 9, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_059_x264, Total Frames: 9, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_abuse\\Abuse009_x264, Total Frames: 5, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_056_x264, Total Frames: 10, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_024_x264, Total Frames: 4, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_010_x264, Total Frames: 11, Sequences: 0\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_018_x264, Total Frames: 8, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_041_x264, Total Frames: 5, Sequences: -1\n",
      "Video: C:\\Users\\Rohini\\capstone_Project\\prjct2\\frames\\frames_normal\\Normal_Videos_015_x264, Total Frames: 4, Sequences: -1\n",
      "Total sequences created: 55, Total sequence labels: 55\n"
     ]
    }
   ],
   "source": [
    "# Debugging the train sequence creation\n",
    "print(\"\\nCreating sequences for training set...\")\n",
    "frame_sequences_train, sequence_labels_train = create_sequences(frame_train, label_train, sequence_length)\n",
    "print(\"\\nSample training sequence paths:\")\n",
    "print(frame_sequences_train[:2])  # Print the first two sequences\n",
    "print(\"\\nSample training labels:\")\n",
    "print(sequence_labels_train[:2])  # Print the first two labels\n",
    "\n",
    "# Debugging the validation sequence creation\n",
    "print(\"\\nCreating sequences for validation set...\")\n",
    "frame_sequences_val, sequence_labels_val = create_sequences(frame_val, label_val, sequence_length)\n",
    "\n",
    "# Debugging the testing sequence creation\n",
    "print(\"\\nCreating sequences for testing set...\")\n",
    "frame_sequences_test, sequence_labels_test = create_sequences(frame_test, label_test, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4c11b3-6d3f-41e0-a679-93127a849e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = VideoSequenceDataset(frame_sequences_train, sequence_labels_train, transform)\n",
    "val_dataset = VideoSequenceDataset(frame_sequences_val, sequence_labels_val, transform)\n",
    "test_dataset = VideoSequenceDataset(frame_sequences_test, sequence_labels_test, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bc55688-58d3-45ce-aacf-2b432c273493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = VideoSequenceDataset(frame_sequences_train, sequence_labels_train, transform)\n",
    "val_dataset = VideoSequenceDataset(frame_sequences_val, sequence_labels_val, transform)\n",
    "test_dataset = VideoSequenceDataset(frame_sequences_test, sequence_labels_test, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92cf3ef5-ad7a-4058-baf7-1cdfcee8c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class TemporalModel(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_dim=256):\n",
    "        super(TemporalModel, self).__init__()\n",
    "        # Pretrained DenseNet-121 as the spatial feature extractor\n",
    "        self.feature_extractor = models.densenet121(pretrained=True)\n",
    "        self.feature_extractor.classifier = nn.Identity()  # Remove the classifier\n",
    "        \n",
    "        # Temporal model: LSTM\n",
    "        self.lstm = nn.LSTM(input_size=1024, hidden_size=hidden_dim, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # Classifier for sequence-level predictions\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, C, H, W = x.size()\n",
    "        \n",
    "        # Flatten sequences for DenseNet\n",
    "        x = x.view(batch_size * seq_len, C, H, W)\n",
    "        features = self.feature_extractor(x)  # Extract spatial features\n",
    "        features = features.view(batch_size, seq_len, -1)  # Reshape for temporal model\n",
    "        \n",
    "        # Process with LSTM\n",
    "        lstm_out, _ = self.lstm(features)\n",
    "        output = self.classifier(lstm_out[:, -1, :])  # Use last LSTM output\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "843af872-d445-4269-a604-e741f533c77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Rohini\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 3  # Adjust based on your dataset\n",
    "hidden_dim = 256\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Initialize model\n",
    "model = TemporalModel(num_classes=num_classes, hidden_dim=hidden_dim)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ad9af2-281f-4987-ae1b-4b25073f370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait before stopping if no improvement.\n",
    "            verbose (bool): If True, prints messages when stopping.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.best_accuracy = 0\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_accuracy):\n",
    "        if val_accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = val_accuracy\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20703ef-c204-4aff-94b9-d5449b7207f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for frame_sequences, labels in train_loader:\n",
    "        frame_sequences, labels = frame_sequences.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(frame_sequences)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for frame_sequences, labels in val_loader:\n",
    "            frame_sequences, labels = frame_sequences.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(frame_sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Check early stopping\n",
    "    early_stopping(val_accuracy)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e05d6-0cd1-4222-ac69-28efa86dc6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
